# iris ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì¸ê³µì‹ ê²½ë§ ëª¨ë¸  

## ì•Œì•„ì•¼ í•˜ëŠ” ê°œë…  
#### 1. iris  
**MLPClassifier**ëŠ” ë¶„ë¥˜ì—ì„œ `í´ë˜ìŠ¤ ê°œìˆ˜ = ì¶œë ¥ ë‰´ëŸ° ìˆ˜`ë¡œ ë§ì¶˜ë‹¤. (ì¶œë ¥ì¸µì€ ì†Œí”„íŠ¸ë§¥ìŠ¤)
- iris.data         : (150, 4) ì‹¤ìˆ˜ íŠ¹ì§•  
- iris.target       : (150,) ì •ìˆ˜ ë ˆì´ë¸” {0, 1, 2} â†’ 3 classes : (150,)ì€ ë„˜íŒŒì´ ë°°ì—´ì˜ ëª¨ì–‘ì„ ë‚˜íƒ€ë‚´ëŠ” í‘œê¸°ì´ë©°, ë’¤ì˜ ì‰¼í‘œëŠ” ì°¨ì›ì´ 1ê°œì„ì„ ë³´ì—¬ì£¼ëŠ” ê²ƒì´ë¯€ë¡œ 1ì°¨ì› ë°°ì—´ì— ì›ì†Œê°€ 150ê°œë¼ëŠ” ì˜ë¯¸ì´ë‹¤. ë§Œì•½ (150, 1) ì´ ëœë‹¤ë©´ 2ì°¨ì›(2D), 150í–‰ 1ì—´ì˜ ì„¸ë¡œ(ì—´) ë²¡í„°ê°€ ëœë‹¤.  
- iris.target_names : ë ˆì´ë¸” ì´ë¦„ ë°°ì—´ â†’ ['setosa', 'versicolor', 'virginica']  

patience  
train  
validation_split  
epochs : ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë°”í€´ ë‹¤ í•™ìŠµí•˜ë©´ 1 ì—í­  
batch : í•œ ë²ˆì— í•™ìŠµì— ì“°ëŠ” ë¬¶ìŒ (ì‘ì„ìˆ˜ë¡ ìì£¼ ê³ ì¹˜ê³ , í´ìˆ˜ë¡ ì•ˆì •ì ì´ë‹¤.)  
loss : í‹€ë¦° ì •ë„ (ì˜¤ì°¨ : ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)  
backprop : ì—­ì „íŒŒ, ì–´ë–¤ ê°€ì¤‘ì¹˜ë¥¼ ì–´ë–»ê²Œ ê³ ì³ì•¼ ë¡œìŠ¤ê°€ ì¤„ì§€ ê³„ì‚°í•˜ëŠ” ì ˆì°¨  
accuracy ì •í™•ë„  

batch_size  
callbacks  
val_accuracy  
<br><br>

## ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°(hyper parameters)/ê¸°ë³¸ê°’  
hidden_layer_sizes=(10,10): ì€ë‹‰ì¸µ êµ¬ì¡°  
activation='relu': í™œì„±í™” í•¨ìˆ˜  
solver='adam': ìµœì í™” ë°©ì‹(ì‘ì€/ì¤‘ê°„ ë°ì´í„°ì— ì í•©)  
alpha=1e-4: L2 ê·œì œ(ê³¼ì í•© ì™„í™”)  
max_iter=1000: ìµœëŒ€ ë°˜ë³µ ìˆ˜  
random_state=None: ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ê°€ ë§¤ ì‹¤í–‰ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ â†’ ì¬í˜„ì„± ì›í•˜ë©´ random_state=42 ì§€ì •  
<br><br>

## ì½”ë“œ ìƒì„¸ í•´ì„¤  
### 1 cell  
```
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

iris = load_iris()
# print(iris)

model = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000)
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)
model.fit(X_train, y_train)
print("model accuracy:", model.score(X_test, y_test))
print("Predictions:", model.predict(X_test))
```
**ë¬´ì—‡ì„ í•˜ëŠ” ì½”ë“œì¸ê°€?**
1. Scikit-learnì˜ MLPClassifier(ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ )ë¡œ Iris(ë¶“ê½ƒ) ë°ì´í„°ì…‹ì„ í•™ìŠµí•œë‹¤.  
2. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ â†’ í•™ìŠµ â†’ ì •í™•ë„(accuracy) í‰ê°€ â†’ í´ë˜ìŠ¤ ì˜ˆì¸¡ê°’ ì¶œë ¥í•œë‹¤.  
<br>

`from sklearn.~`  
ë¶„ë¥˜ìš© ë‹¤ì¸µí¼ì…‰íŠ¸ë¡ (MLPClassifier), iris ë°ì´í„° ë¡œë”(load_iris), ë°ì´í„°  ë¶„í•  ìœ í‹¸(train_test_split)ì„ ë¶ˆëŸ¬ì˜¨ë‹¤.  

`iris = load_iris()`  
ë°ì´í„°ì…‹ì„ ë¡œë“œí•œë‹¤.  

`model = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000)`  
MLP ë¶„ë¥˜ê¸°ë¥¼ ìƒì„±í•œë‹¤.  
- `iris.data` ì…ë ¥ íŠ¹ì„±ì´ 4ê°œì—¬ì„œ, input ë‰´ëŸ°ì€ 4ê°œë¡œ ì‹œì‘í•œë‹¤.  
- `hidden_layer_sizes=(10, 10)` ì€ ì€ë‹‰ì¸µ 2ê°œì´ë©°, ê° 10ê°œì˜ ë‰´ëŸ°ì„ ìƒì„±í•œë‹¤.  
- `iris.target` ì¶œë ¥ íŠ¹ì„±ì´ 3ê°œì—¬ì„œ, output ë‰´ëŸ°ì€ 3ê°œê°€ ëœë‹¤.  
![neural_network](./images/neural_network.png)  
- ìµœëŒ€ ë°˜ë³µ 1000 epoch(ì •í™•íˆëŠ” scikit-learnì˜ ë°˜ë³µ ìŠ¤í…)  
- ê¸°ë³¸ê°’ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

| key                | value    |
| ------------------ | -------- |
| activation         | relu     |
| solver             | adam     |
| alpha              | 1e-4(L2) |
| learning_rate_init | 1e-3     |
| early_stopping     | False    |
| random_state       | None     | 

`X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)`  
**iris.data**ì™€ **iris.target**ì—ëŠ” 150ê°œì˜ ìƒ˜í”Œì´ ìˆê³ , test_size=0.2 ëŠ” í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ì´ **20%**ë¼ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.  
20% ì¦‰ 8:2 ë¹„ìœ¨ë¡œ ë¶„í• í•˜ë©´ 150ê°œì˜ ìƒ˜í”Œì˜ í…ŒìŠ¤íŠ¸ëŠ” 30ê°œê°€ ëœë‹¤. (í•™ìŠµ 120, í…ŒìŠ¤íŠ¸ 30)  
(ps. _test_size_ë¥¼ ì •ìˆ˜ë¡œ ì£¼ë©´ ì •í™•íˆ ê·¸ ê°œìˆ˜ë§Œí¼ í…ŒìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•œë‹¤. ex: _test_size=30_)  
`random_state=42` â†’ í•­ìƒ ê°™ì€ ë¶„í• ì„ ì‚¬ìš©í•˜ë„ë¡ ëœë¤í•œ ë™ì‘ì˜ seedë¥¼ ê³ ì •í•œë‹¤. `train_test_split`ì€ ë°ì´í„°ë¥¼ ì„ì–´ì„œ(ì…”í”Œ) í•™ìŠµ/í…ŒìŠ¤íŠ¸ë¥¼ ë‚˜ëˆ„ëŠ”ë°, ì´ë•Œ ì“°ëŠ” ë‚œìˆ˜ ìƒì„±ê¸°ì˜ ì‹œì‘ê°’(seed)ì„ 42ë¡œ ê³ ì •í•˜ë©´ í•­ìƒ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì„ì´ê¸° ë•Œë¬¸ì— ë§¤ë²ˆ ê°™ì€ ë¶„í•  ê²°ê³¼(ê°™ì€ ìƒ˜í”Œì´ í•™ìŠµ/í…ŒìŠ¤íŠ¸ë¡œ ê°)ë¥¼ ì–»ëŠ”ë‹¤. : ê°™ì€ ì½”ë“œ/ë°ì´í„°ë¡œ í•­ìƒ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•œ ì¬í˜„ì„± í•„ìš”ì‹œ ì‚¬ìš©í•œë‹¤. ex, ì‹¤í—˜ ê¸°ë¡/ë¹„êµ  

`model.fit(X_train, y_train)`  
ì‹ ê²½ë§ í•™ìŠµì„ ì‹œì‘í•œë‹¤. ì˜ˆì¸¡ > í‹€ë¦° ê²ƒ í™•ì¸(loss) > ìˆ˜ì •(ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸) ìˆœì„œë¥¼ ê³„ì†í•´ì„œ ë°˜ë³µí•œë‹¤.  
1. ë°ì´í„°ë¥¼ ì„ê³ (shuffle) Adam ì˜µí‹°ë§ˆì´ì €ë¡œ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ ì²˜ë¦¬í•œë‹¤.  
2. ì˜ˆì¸¡ `ìˆœì „íŒŒ, forward`  
- ì…ë ¥(4) â†’ ì€ë‹‰ì¸µ(10) â†’ ì€ë‹‰ì¸µ(10) â†’ ì¶œë ¥(3) ìˆœì„œë¡œ ê°’ì„ ë³´ë‚´ ê° í´ë˜ìŠ¤ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤.  
3. ì˜¤ì°¨ í™•ì¸ `loss`  
- ì˜ˆì¸¡ê³¼ ì •ë‹µ(y_train)ì„ ë¹„êµí•´ì„œ ì˜¤ì°¨(loss)ë¥¼ êµ¬í•œë‹¤.  
4. ì˜¤ì°¨ ì¶”ì  `ì—­ì „íŒŒ, backprop`  
- ì˜¤ì°¨ê°€ ê° ê°€ì¤‘ì¹˜, ë°”ì´ì–´ìŠ¤ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë°›ì•˜ëŠ”ì§€ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•œë‹¤.  
5. ì—…ë°ì´íŠ¸  
- Adam ì˜µí‹°ë§ˆì´ì €ê°€ ê¸°ìš¸ê¸°ë§Œí¼ ê°€ì¤‘ì¹˜/ë°”ì´ì–´ìŠ¤ë¥¼ ì‚´ì§ ë³€ê²½í•œë‹¤.  
- ì—¬ëŸ¬ ë°°ì¹˜, ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•œë‹¤.  
ìœ„ ê³¼ì •ì„ ê³„ì† ë°˜ë³µí• ìˆ˜ë¡ ì˜¤ì°¨ê°€ ì ì  ì ì–´ì ¸ ì •ë‹µ í´ë˜ìŠ¤ì˜ ì ìˆ˜(í™•ë¥ )ê°€ ì˜¬ë¼ê°€ë„ë¡ ì¡°ì •ëœë‹¤.  

`print("model accuracy:", model.score(X_test, y_test))`  
í…ŒìŠ¤íŠ¸ì…‹ **ì •í™•ë„**ë¥¼ ì¶œë ¥í•œë‹¤. (scoreëŠ” ê¸°ë³¸ìœ¼ë¡œ accuracyë¥¼ ë°˜í™˜)  
ì¶œë ¥ì€ 0ê³¼ 1 ì‚¬ì´ì˜ ì‹¤ìˆ˜ì´ë©°, `ë§ì¶˜ ê°œìˆ˜ / ì „ì²´ ê°œìˆ˜`ë¡œ ê³„ì‚°í•œë‹¤.  

`print("Predictions:", model.predict(X_test))`  
í…ŒìŠ¤íŠ¸ì…‹ì— ëŒ€í•œ **ì˜ˆì¸¡ ë ˆì´ë¸” ë°°ì—´**ì„ ì¶œë ¥í•œë‹¤.  
ì¶œë ¥ì€ `ê¸¸ì´ = í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜`ì´ê³ , ê° ë ˆì´ë¸”ì˜ ìˆ«ì(0, 1, 2)ëŠ” í’ˆì¢… í´ë˜ìŠ¤ë¥¼ ì˜ë¯¸í•œë‹¤.  
> í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³´ê³  ì‹¶ë‹¤ë©´ `names = iris.target_names` ì„ ì‚¬ìš©í•œë‹¤.  
> > í´ë˜ìŠ¤ ì´ë¦„ : ['setosa', 'versicolor', 'virginica']   

ğŸ’¡ Point!
- score() = ì •í™•ë„ = ë§ì¶˜ë¹„ìœ¨  
- predict() = ê° ìƒ˜í”Œì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë°°ì—´  
<br> 

### 2 cell
```
from sklearn.metrics import confusion_matrix
print("Confusion Matrix:\n", confusion_matrix(y_test, model.predict(X_test)))
```
<br>

### 3 cell
```
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Input

model = Sequential()
model.add(Input(shape=(4,))) # input layer
model.add(Dense(50, activation='sigmoid')) # hidden layer
model.add(Dense(30, activation='sigmoid')) # hidden layer
model.add(Dense(3, activation='softmax')) # output layer
model.summary()
```
<br>

### 4 cell
```
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=100, batch_size=50)
```
<br>

### 5 cell
```
print(model.evaluate(X_test, y_test))
```
<br>

### 6 cell
```
model.save('iris_model.keras')
```
<br>

### 7 cell
```
from tensorflow.keras.models import load_model
loaded_model = load_model('iris_model.keras')
```
<br>

### 8 cell
```
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)

print(loaded_model.evaluate(X_test, y_test))
```