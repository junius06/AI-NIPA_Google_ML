# iris ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì¸ê³µì‹ ê²½ë§ ëª¨ë¸  

## ì•Œì•„ì•¼ í•˜ëŠ” ê°œë…  
#### 1. iris  
**MLPClassifier**ëŠ” ë¶„ë¥˜ì—ì„œ `í´ë˜ìŠ¤ ê°œìˆ˜ = ì¶œë ¥ ë‰´ëŸ° ìˆ˜`ë¡œ ë§ì¶˜ë‹¤. (ì¶œë ¥ì¸µì€ ì†Œí”„íŠ¸ë§¥ìŠ¤)
- iris.data         : (150, 4) ì‹¤ìˆ˜ íŠ¹ì§•  
- iris.target       : (150,) ì •ìˆ˜ ë ˆì´ë¸” {0, 1, 2} â†’ 3 classes : (150,)ì€ ë„˜íŒŒì´ ë°°ì—´ì˜ ëª¨ì–‘ì„ ë‚˜íƒ€ë‚´ëŠ” í‘œê¸°ì´ë©°, ë’¤ì˜ ì‰¼í‘œëŠ” ì°¨ì›ì´ 1ê°œì„ì„ ë³´ì—¬ì£¼ëŠ” ê²ƒì´ë¯€ë¡œ 1ì°¨ì› ë°°ì—´ì— ì›ì†Œê°€ 150ê°œë¼ëŠ” ì˜ë¯¸ì´ë‹¤. ë§Œì•½ (150, 1) ì´ ëœë‹¤ë©´ 2ì°¨ì›(2D), 150í–‰ 1ì—´ì˜ ì„¸ë¡œ(ì—´) ë²¡í„°ê°€ ëœë‹¤.  
- iris.target_names : ë ˆì´ë¸” ì´ë¦„ ë°°ì—´ â†’ ['setosa', 'versicolor', 'virginica']  

patience  
train  
validation_split  
epochs : ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë°”í€´ ë‹¤ í•™ìŠµí•˜ë©´ 1 ì—í­  
batch : í•œ ë²ˆì— í•™ìŠµì— ì“°ëŠ” ë¬¶ìŒ (ì‘ì„ìˆ˜ë¡ ìì£¼ ê³ ì¹˜ê³ , í´ìˆ˜ë¡ ì•ˆì •ì ì´ë‹¤.)  
loss : í‹€ë¦° ì •ë„ (ì˜¤ì°¨ : ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)  
backprop : ì—­ì „íŒŒ, ì–´ë–¤ ê°€ì¤‘ì¹˜ë¥¼ ì–´ë–»ê²Œ ê³ ì³ì•¼ ë¡œìŠ¤ê°€ ì¤„ì§€ ê³„ì‚°í•˜ëŠ” ì ˆì°¨  
accuracy ì •í™•ë„  

batch_size  
callbacks  
val_accuracy  
<br><br>

## ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°(hyper parameters)/ê¸°ë³¸ê°’  
hidden_layer_sizes=(10,10): ì€ë‹‰ì¸µ êµ¬ì¡°  
activation='relu': í™œì„±í™” í•¨ìˆ˜  
solver='adam': ìµœì í™” ë°©ì‹(ì‘ì€/ì¤‘ê°„ ë°ì´í„°ì— ì í•©)  
alpha=1e-4: L2 ê·œì œ(ê³¼ì í•© ì™„í™”)  
max_iter=1000: ìµœëŒ€ ë°˜ë³µ ìˆ˜  
random_state=None: ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ê°€ ë§¤ ì‹¤í–‰ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ â†’ ì¬í˜„ì„± ì›í•˜ë©´ random_state=42 ì§€ì •  
<br><br>

## ì½”ë“œ ìƒì„¸ í•´ì„¤  
### 1 cell  
```
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

iris = load_iris()
# print(iris)

model = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000)
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)
model.fit(X_train, y_train)
print("model accuracy:", model.score(X_test, y_test))
print("Predictions:", model.predict(X_test))
```
**ë¬´ì—‡ì„ í•˜ëŠ” ì½”ë“œì¸ê°€?**
1. Scikit-learnì˜ MLPClassifier(ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ )ë¡œ Iris(ë¶“ê½ƒ) ë°ì´í„°ì…‹ì„ í•™ìŠµí•œë‹¤.  
2. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ â†’ í•™ìŠµ â†’ ì •í™•ë„(accuracy) í‰ê°€ â†’ í´ë˜ìŠ¤ ì˜ˆì¸¡ê°’ ì¶œë ¥í•œë‹¤.  
<br>

`from sklearn.~`  
ë¶„ë¥˜ìš© ë‹¤ì¸µí¼ì…‰íŠ¸ë¡ (MLPClassifier), iris ë°ì´í„° ë¡œë”(load_iris), ë°ì´í„°  ë¶„í•  ìœ í‹¸(train_test_split)ì„ ë¶ˆëŸ¬ì˜¨ë‹¤.  

`iris = load_iris()`  
ë°ì´í„°ì…‹ì„ ë¡œë“œí•œë‹¤.  

`model = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000)`  
MLP ë¶„ë¥˜ê¸°ë¥¼ ìƒì„±í•œë‹¤.  
- `iris.data` ì…ë ¥ íŠ¹ì„±ì´ 4ê°œì—¬ì„œ, input ë‰´ëŸ°ì€ 4ê°œë¡œ ì‹œì‘í•œë‹¤.  
- `hidden_layer_sizes=(10, 10)` ì€ ì€ë‹‰ì¸µ 2ê°œì´ë©°, ê° 10ê°œì˜ ë‰´ëŸ°ì„ ìƒì„±í•œë‹¤.  
- `iris.target` ì¶œë ¥ íŠ¹ì„±ì´ 3ê°œì—¬ì„œ, output ë‰´ëŸ°ì€ 3ê°œê°€ ëœë‹¤.  
![neural_network](./images/neural_network.png)  
- ìµœëŒ€ ë°˜ë³µ 1000 epoch(ì •í™•íˆëŠ” scikit-learnì˜ ë°˜ë³µ ìŠ¤í…)  
- ê¸°ë³¸ê°’ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

| key                | value    |
| ------------------ | -------- |
| activation         | relu     |
| solver             | adam     |
| alpha              | 1e-4(L2) |
| learning_rate_init | 1e-3     |
| early_stopping     | False    |
| random_state       | None     | 

`X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)`  
**iris.data**ì™€ **iris.target**ì—ëŠ” 150ê°œì˜ ìƒ˜í”Œì´ ìˆê³ , test_size=0.2 ëŠ” í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ì´ **20%**ë¼ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.  
20% ì¦‰ 8:2 ë¹„ìœ¨ë¡œ ë¶„í• í•˜ë©´ 150ê°œì˜ ìƒ˜í”Œì˜ í…ŒìŠ¤íŠ¸ëŠ” 30ê°œê°€ ëœë‹¤. (í•™ìŠµ 120, í…ŒìŠ¤íŠ¸ 30)  
(ps. _test_size_ë¥¼ ì •ìˆ˜ë¡œ ì£¼ë©´ ì •í™•íˆ ê·¸ ê°œìˆ˜ë§Œí¼ í…ŒìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•œë‹¤. ex: _test_size=30_)  
`random_state=42` â†’ í•­ìƒ ê°™ì€ ë¶„í• ì„ ì‚¬ìš©í•˜ë„ë¡ ëœë¤í•œ ë™ì‘ì˜ seedë¥¼ ê³ ì •í•œë‹¤. `train_test_split`ì€ ë°ì´í„°ë¥¼ ì„ì–´ì„œ(ì…”í”Œ) í•™ìŠµ/í…ŒìŠ¤íŠ¸ë¥¼ ë‚˜ëˆ„ëŠ”ë°, ì´ë•Œ ì“°ëŠ” ë‚œìˆ˜ ìƒì„±ê¸°ì˜ ì‹œì‘ê°’(seed)ì„ 42ë¡œ ê³ ì •í•˜ë©´ í•­ìƒ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì„ì´ê¸° ë•Œë¬¸ì— ë§¤ë²ˆ ê°™ì€ ë¶„í•  ê²°ê³¼(ê°™ì€ ìƒ˜í”Œì´ í•™ìŠµ/í…ŒìŠ¤íŠ¸ë¡œ ê°)ë¥¼ ì–»ëŠ”ë‹¤. : ê°™ì€ ì½”ë“œ/ë°ì´í„°ë¡œ í•­ìƒ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•œ ì¬í˜„ì„± í•„ìš”ì‹œ ì‚¬ìš©í•œë‹¤. ex, ì‹¤í—˜ ê¸°ë¡/ë¹„êµ  

`model.fit(X_train, y_train)`  
ì‹ ê²½ë§ í•™ìŠµì„ ì‹œì‘í•œë‹¤. ì˜ˆì¸¡ > í‹€ë¦° ê²ƒ í™•ì¸(loss) > ìˆ˜ì •(ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸) ìˆœì„œë¥¼ ê³„ì†í•´ì„œ ë°˜ë³µí•œë‹¤.  
1. ë°ì´í„°ë¥¼ ì„ê³ (shuffle) Adam ì˜µí‹°ë§ˆì´ì €ë¡œ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ ì²˜ë¦¬í•œë‹¤.  
2. ì˜ˆì¸¡ `ìˆœì „íŒŒ, forward`  
- ì…ë ¥(4) â†’ ì€ë‹‰ì¸µ(10) â†’ ì€ë‹‰ì¸µ(10) â†’ ì¶œë ¥(3) ìˆœì„œë¡œ ê°’ì„ ë³´ë‚´ ê° í´ë˜ìŠ¤ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤.  
3. ì˜¤ì°¨ í™•ì¸ `loss`  
- ì˜ˆì¸¡ê³¼ ì •ë‹µ(y_train)ì„ ë¹„êµí•´ì„œ ì˜¤ì°¨(loss)ë¥¼ êµ¬í•œë‹¤.  
4. ì˜¤ì°¨ ì¶”ì  `ì—­ì „íŒŒ, backprop`  
- ì˜¤ì°¨ê°€ ê° ê°€ì¤‘ì¹˜, ë°”ì´ì–´ìŠ¤ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë°›ì•˜ëŠ”ì§€ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•œë‹¤.  
5. ì—…ë°ì´íŠ¸  
- Adam ì˜µí‹°ë§ˆì´ì €ê°€ ê¸°ìš¸ê¸°ë§Œí¼ ê°€ì¤‘ì¹˜/ë°”ì´ì–´ìŠ¤ë¥¼ ì‚´ì§ ë³€ê²½í•œë‹¤.  
- ì—¬ëŸ¬ ë°°ì¹˜, ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•œë‹¤.  
ìœ„ ê³¼ì •ì„ ê³„ì† ë°˜ë³µí• ìˆ˜ë¡ ì˜¤ì°¨ê°€ ì ì  ì ì–´ì ¸ ì •ë‹µ í´ë˜ìŠ¤ì˜ ì ìˆ˜(í™•ë¥ )ê°€ ì˜¬ë¼ê°€ë„ë¡ ì¡°ì •ëœë‹¤.  

`print("model accuracy:", model.score(X_test, y_test))`  
í…ŒìŠ¤íŠ¸ì…‹ **ì •í™•ë„**ë¥¼ ì¶œë ¥í•œë‹¤. (scoreëŠ” ê¸°ë³¸ìœ¼ë¡œ accuracyë¥¼ ë°˜í™˜)  
ì¶œë ¥ì€ 0ê³¼ 1 ì‚¬ì´ì˜ ì‹¤ìˆ˜ì´ë©°, `ë§ì¶˜ ê°œìˆ˜ / ì „ì²´ ê°œìˆ˜`ë¡œ ê³„ì‚°í•œë‹¤.  

`print("Predictions:", model.predict(X_test))`  
í…ŒìŠ¤íŠ¸ì…‹ì— ëŒ€í•œ **ì˜ˆì¸¡ ë ˆì´ë¸” ë°°ì—´**ì„ ì¶œë ¥í•œë‹¤.  
ì¶œë ¥ì€ `ê¸¸ì´ = í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜`ì´ê³ , ê° ë ˆì´ë¸”ì˜ ìˆ«ì(0, 1, 2)ëŠ” í’ˆì¢… í´ë˜ìŠ¤ë¥¼ ì˜ë¯¸í•œë‹¤.  
> í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³´ê³  ì‹¶ë‹¤ë©´ `names = iris.target_names` ì„ ì‚¬ìš©í•œë‹¤.  
> > í´ë˜ìŠ¤ ì´ë¦„ : ['setosa', 'versicolor', 'virginica']   
<br>

ğŸ’¡ **Point!**
- score() = ì •í™•ë„ = ë§ì¶˜ë¹„ìœ¨  
- predict() = ê° ìƒ˜í”Œì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë°°ì—´  
<br>


### 2 cell
```
from sklearn.metrics import confusion_matrix
print("Confusion Matrix:\n", confusion_matrix(y_test, model.predict(X_test)))
```
**ë¬´ì—‡ì„ í•˜ëŠ” ì½”ë“œì¸ê°€?**  
1. confusion matrixë¥¼ ê³„ì‚°í•´ì„œ ì¶œë ¥í•œë‹¤.  
2. `X_test`ì— ëŒ€í•œ ì˜ˆì¸¡ ë ˆì´ë¸”ì„ ì¦‰ì„ì—ì„œ ë§Œë“¤ê³ (`model.predict(X_test)`), ê·¸ ì˜ˆì¸¡ê³¼ ì‹¤ì œ ì •ë‹µ `y_test`ë¥¼ ë¹„êµí•´ confusion matrixë¥¼ ê³„ì‚°í•œ ë’¤ ì¶œë ¥í•œë‹¤.  
3. confusion matrixëŠ” í–‰=ì‹¤ì œ í´ë˜ìŠ¤, ì—´=ì˜ˆì¸¡ í´ë˜ìŠ¤ ì´ë©°, ê° ì¹¸ì€ í•´ë‹¹ ì¡°í•©ì˜ ê°œìˆ˜ì´ë‹¤.  
<br>

`from sklearn.matrix import confusion_matrix`  
scikit-learnì˜ metrics ëª¨ë“ˆì—ì„œ confusion_matrixë¥¼ ê°€ì ¸ì™€ì„œ, confusion_matrix(...)ë¥¼ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ìˆê²Œ ëœë‹¤.  
`print("Confusion Matrix:\n", confusion_matrix(y_test, model.predict(X_test)))`  
- ì‹¤í–‰ ìˆœì„œ  
  - `model.predict(X_test)` â†’ í…ŒìŠ¤íŠ¸ì…‹ ê° ìƒ˜í”Œì˜ ì˜ˆì¸¡ ë ˆì´ë¸” ë°°ì—´ì„ ë§Œë“ ë‹¤.  
  - `confusion_matrix(y_test, <ì˜ˆì¸¡ë°°ì—´>)` â†’ í–‰ = ì‹¤ì œ ë ˆì´ë¸”(y_test), ì—´ = ì˜ˆì¸¡ ë ˆì´ë¸” ê¸°ì¤€ì˜ **ë¹ˆë„í‘œ(ì •ìˆ˜ í–‰ë ¬)**ë¥¼ ê³„ì‚°í•œë‹¤.  
    - í¬ê¸° : `n_classes x n_classes` (irisëŠ” ë³´í†µ 3x3)  
    - ëŒ€ê°ì„  = ë§ì¶˜ ê°œìˆ˜, ëŒ€ê°ì„  ë°– = ì˜¤ë¶„ë¥˜ ê°œìˆ˜  
    - ë ˆì´ë¸” ìˆœì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì •ë ¬ëœ ê³ ìœ ê°’ ìˆœì„œë¥¼ ì‚¬ìš©í•œë‹¤.  
<br>


### 3 cell
```
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Input

model = Sequential()
model.add(Input(shape=(4,))) # input layer
model.add(Dense(50, activation='sigmoid')) # hidden layer
model.add(Dense(30, activation='sigmoid')) # hidden layer
model.add(Dense(3, activation='softmax')) # output layer
model.summary()
```
<br>

**ë¬´ì—‡ì„ í•˜ëŠ” ì½”ë“œì¸ê°€?**  
1. Kerasë¡œ ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ (MLP) ë¶„ë¥˜ ëª¨ë¸ì˜ êµ¬ì¡°ë§Œ ì •ì˜í•˜ê³  ìš”ì•½ì„ ì¶œë ¥í•œë‹¤.  
<br>

`from tensorflow.keras import Sequential`  
Kerasì˜ Sequential í´ë˜ìŠ¤ëŠ” layerë“¤ì„ **ìœ„ì—ì„œ ì•„ë˜ë¡œ ìˆœì°¨ì ìœ¼ë¡œ** ìŒ“ëŠ” ëª¨ë¸ì„ ë§Œë“¤ ë•Œ ì‚¬ìš©í•œë‹¤.  

`from tensorflow.keras.layers import Dense, Input`  
Dense : ì™„ì „ ì—°ê²°(fully connected) ì¸µ  
Input : ì…ë ¥ í…ì„œì˜ ëª¨ì–‘(shape)ì„ ì„ ì–¸í•˜ëŠ” ì¸µ(ë°°ì¹˜ ì°¨ì› ì œì™¸)  

`model = Sequential()`  
ë¹ˆ Sequential ëª¨ë¸ì„ ìƒì„±í•œë‹¤. ì´ì œ add()ë¡œ ì¸µì„ ì°¨ë¡€ëŒ€ë¡œ ë¶™ì¼ ìˆ˜ ìˆë‹¤.  

`model.add(Input(shape=(4,))) # input layer`  
ì…ë ¥ì˜ í˜•ìƒì„ ì§€ì •í•œë‹¤. ê° ìƒ˜í”Œì€ ê¸¸ì´ 4ì˜ ë²¡í„°ë¥¼ ê°–ëŠ”ë‹¤.  
ë°°ì¹˜ ì°¨ì›ì€ ì œì™¸í•˜ë¯€ë¡œ, ì‹¤ì œ ì…ë ¥ ëª¨ì–‘ì€ `(batch_size, 4)`ê°€ ëœë‹¤.  
ì—¬ê¸°ì„œëŠ” í•™ìŠµ íŒŒë¼ë¯¸í„°ì¸ ê°€ì¤‘ì¹˜ë¥¼ ê°–ì§€ ì•ŠëŠ”ë‹¤.  

`model.add(Dense(50, activation='sigmoid')) # hidden layer`  
ìœ ë‹› 50ê°œì˜ ì€ë‹‰ì¸µì„ ì¶”ê°€í•œë‹¤.  
í™œì„±í™” í•¨ìˆ˜ëŠ” `sigmoid`ì´ë©°, ì´ì „ ì¸µì˜ ëª¨ë“  ë‰´ëŸ°ê³¼ ì™„ì „ ì—°ê²°ëœë‹¤.  

`model.add(Dense(30, activation='sigmoid')) # hidden layer`  
ìœ ë‹› 30ê°œì˜ ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µìœ¼ë¡œ, í™œì„±í™” í•¨ìˆ˜ëŠ” `sigmoid`ì´ë‹¤.  

`model.add(Dense(3, activation='softmax')) # output layer`  
ìœ ë‹› 3ê°œì˜ ì¶œë ¥ì¸µ, `softmax`ë¡œ ê° í´ë˜ìŠ¤ì˜ í™•ë¥ (í•©=1)ì„ ì¶œë ¥í•œë‹¤.  
ë³´í†µ 3-classses ë¶„ë¥˜ ë¬¸ì œë¥¼ ëŒ€ì‘í•  ë•Œ ì´ëŸ¬í•œ í˜•íƒœë¥¼ ì‚¬ìš©í•œë‹¤.  

`model.summary()`  
ëª¨ë¸ êµ¬ì¡° ìš”ì•½ì„ ì¶œë ¥í•œë‹¤. - ê° ì¸µì˜ ì¶œë ¥ í˜•íƒœ, íŒŒë¼ë¯¸í„° ìˆ˜, ì´ íŒŒë¼ë¯¸í„° ìˆ˜ ë“±.  

- ì°¸ê³ ) íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚° ì˜ˆì‹œ
  - Dense(50) : (ì…ë ¥ 4 x ìœ ë‹› 50) + ë°”ì´ì–´ìŠ¤ 50 = 4*50 + 50 = 250  
  - Dense(30) : (50 x 30) + 30 = 1530  
  - Dense(3)  : (30 x 3) + 3 = 93  
  - ì´í•© : 250 + 1530 + 93 = 1873 (Inputì¸µì€ íŒŒë¼ë¯¸í„°ê°€ ì—†ë‹¤.)  
    - ì—¬ê¸°ì„œ ìœ ë‹›(unit)ì´ë€ ë‰´ëŸ°(node) 1ê°œë¥¼ ì˜ë¯¸í•œë‹¤.  

### 4 cell
```
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=100, batch_size=50)
```
<br>

### 5 cell
```
print(model.evaluate(X_test, y_test))
```
<br>

### 6 cell
```
model.save('iris_model.keras')
```
<br>

### 7 cell
```
from tensorflow.keras.models import load_model
loaded_model = load_model('iris_model.keras')
```
<br>

### 8 cell
```
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)

print(loaded_model.evaluate(X_test, y_test))
```